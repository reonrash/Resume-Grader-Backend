📄 Resume Grader BackendThis project provides a robust backend for a resume grading and augmentation application, leveraging the power of Google's Gemini Large Language Model (LLM) for intelligent text processing. It serves as a practical example for integrating AI capabilities into a modern web service, focusing on FastAPI for API development.✨ FeaturesThis backend exposes three primary API routes, each designed to assist with resume optimization:/augment (POST):Purpose: Rewrites a given resume bullet point into three augmented options.LLM Role: Utilizes the LLM to generate improved bullet points that maximize impact through strong action verbs, quantifiable achievements, skill relevance, and clarity, adhering to a specified length.Input: JSON body containing an original_bullet_point string.Output: JSON object with a list of three augmented bullet point options./grader (POST):Purpose: Provides a comprehensive assessment of a resume.LLM Role: Acts as an "expert resume evaluator" to grade the resume based on criteria like ATS-friendly formatting, clarity, quantifiable impact, keyword relevance, and brevity.Input: File upload (PDF, DOCX, or TXT) containing the resume content.Output: Detailed JSON assessment including Keywords, SectionFormatting, ClarityAction, QuantifiableImpact, KeywordRelevance, BrevityFormatting, Grade, Score, Highlights, and Improvements./comparison (POST):Purpose: Compares a resume against a specific job application description.LLM Role: Functions as a "seasoned technical recruiter and resume coach" to analyze the alignment between the resume and job description.Input: File upload (PDF, DOCX, or TXT) for the resume and a text field for the job_application_text.Output: JSON object containing a Grade, Keyword difference, Skill Gap Analysis, Impact & Clarity Gap, and Recommendations for tailoring the resume.All responses are generated by the LLM in a structured JSON format, making this project an excellent demonstration of prompt engineering and AI-driven content generation in a backend service.Note on Validation: FastAPI automatically provides robust request and response type validation using Pydantic models and Python type hints, ensuring data integrity and clear API contracts.🚀 Technologies UsedFastAPI: A modern, fast (high-performance) web framework for building APIs with Python 3.7+.Uvicorn: An ASGI server for running FastAPI applications.Google Generative AI (google-generativeai): Python client library for interacting with Google's Gemini LLM.PyPDF (pypdf): For extracting text from PDF files.Python-DOCX (python-docx): For extracting text from Microsoft Word (.docx) files.Python-Dotenv (python-dotenv): For loading environment variables from a .env file.⚙️ Setup and RunningPrerequisitesPython 3.9+Docker (recommended for deployment)A Google Gemini API Key (obtainable from Google AI Studio)1. Environment SetupClone the repository (or create the files main.py, requirements.txt, Dockerfile in a directory).Create a .env file in the root of your project directory. This file will store your Gemini API key.GOOGLE_API_KEY="YOUR_GEMINI_API_KEY_HERE"
Replace YOUR_GEMINI_API_KEY_HERE with your actual API key.2. Running Locally (Without Docker - For Development)Install dependencies:pip install -r requirements.txt
Run the FastAPI application:uvicorn main:app --reload --host 127.0.0.1 --port 8000
The --reload flag enables hot-reloading during development.You can access the interactive API documentation at http://127.0.0.1:8000/docs.3. Running with Docker (Recommended for Deployment)Build the Docker image:Navigate to your project root directory (where Dockerfile, main.py, and requirements.txt are located) and run:docker build -t resume-grader-backend .
This command builds a Docker image named resume-grader-backend.Run the Docker container:To run the container and pass your GOOGLE_API_KEY from the .env file:docker run -d -p 8000:8000 --env-file ./.env resume-grader-backend
-d: Runs the container in detached mode (in the background).-p 8000:8000: Maps port 8000 on your host machine to port 8000 inside the container.--env-file ./.env: Instructs Docker to load environment variables from your local .env file into the container.Your API will now be accessible at http://localhost:8000. You can view the interactive API documentation at http://localhost:8000/docs.🧪 Testing with PostmanYou can test each route using a tool like Postman./augment (POST):URL: http://localhost:8000/augmentBody: raw -> JSON{
"bullet_point": "Managed team tasks and reported progress."
}
/grader (POST):URL: http://localhost:8000/graderBody: form-dataKey: file (select "File" type)Value: Upload a .pdf, .docx, or .txt resume file./comparison (POST):URL: http://localhost:8000/comparisonBody: form-dataKey 1: file (select "File" type), upload your resume file.Key 2: job_application_text (select "Text" type), paste the job description text.🛑 Shutting Down the Docker ContainerTo stop and remove your running Docker container:Find the container ID or name:docker ps
Look for resume-grader-backend or its CONTAINER ID.Stop the container:docker stop <CONTAINER_ID_OR_NAME>
Example: docker stop resume-grader-backendRemove the container:docker rm <CONTAINER_ID_OR_NAME>
Example: docker rm resume-grader-backendAlternatively, to stop and remove in one command (use with caution):docker rm -f resume-grader-backend
